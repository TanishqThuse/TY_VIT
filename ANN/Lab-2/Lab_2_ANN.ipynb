{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name : Tanishq Thuse\n",
        "\n",
        "Subject : ANN\n",
        "\n",
        "Roll no. : 52"
      ],
      "metadata": {
        "id": "mN3VTfi4kixi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Perceptron class\n",
        "class Perceptron:\n",
        "    def __init__(self, num_inputs, learning_rate=0.1):\n",
        "        self.weights = np.random.rand(num_inputs) * 2 - 1  # Initialize weights randomly between -1 and 1\n",
        "        self.bias = np.random.rand() * 2 - 1              # Initialize bias randomly between -1 and 1\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def activate(self, inputs):\n",
        "        # Step activation function\n",
        "        return 1 if np.dot(inputs, self.weights) + self.bias >= 0 else 0\n",
        "\n",
        "    def train(self, training_data, labels, epochs):\n",
        "        for _ in range(epochs):\n",
        "            for inputs, label in zip(training_data, labels):\n",
        "                prediction = self.activate(inputs)\n",
        "                error = label - prediction\n",
        "                # Update weights and bias\n",
        "                self.weights += self.learning_rate * error * inputs\n",
        "                self.bias += self.learning_rate * error\n",
        "\n",
        "# Function to convert a number's ASCII representation to a feature vector\n",
        "def number_to_features(number_str):\n",
        "    # Simple approach: use the ASCII values of the digits as features.\n",
        "    # This is a very basic representation for illustrative purposes.\n",
        "\n",
        "    features = [ord(char) for char in number_str]\n",
        "    return np.array(features)\n",
        "\n",
        "# Training data: ASCII representation of numbers and their labels (0 for even, 1 for odd)\n",
        "# We'll use a few examples. In a real scenario, you'd need a larger, more diverse dataset.\n",
        "training_numbers = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\"]\n",
        "# Labels: 0 for even, 1 for odd\n",
        "training_labels = [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
        "\n",
        "# Test data\n",
        "test_numbers = [\"12\", \"13\", \"100\", \"101\", \"25\", \"36\"]\n",
        "\n",
        "# Convert all numbers (training and test) to feature vectors to determine max_len\n",
        "all_numbers = training_numbers + test_numbers\n",
        "all_features = [number_to_features(num) for num in all_numbers]\n",
        "\n",
        "# Determine the maximum length of the feature vectors\n",
        "max_len = max(len(features) for features in all_features)\n",
        "\n",
        "# Convert training numbers to feature vectors and pad\n",
        "training_data = []\n",
        "for num in training_numbers:\n",
        "    features = number_to_features(num)\n",
        "    padded_features = np.pad(features, (0, max_len - len(features)), 'constant')\n",
        "    training_data.append(padded_features)\n",
        "training_data = np.array(training_data)\n",
        "\n",
        "# Create and train the Perceptron\n",
        "# The number of inputs is the length of the padded feature vector\n",
        "num_inputs = max_len\n",
        "perceptron = Perceptron(num_inputs)\n",
        "\n",
        "epochs = 100  # Number of training epochs\n",
        "perceptron.train(training_data, training_labels, epochs)\n",
        "\n",
        "# Test the trained Perceptron\n",
        "print(\"Testing the Perceptron:\")\n",
        "for number_str in test_numbers:\n",
        "    test_features = number_to_features(number_str)\n",
        "    padded_test_features = np.pad(test_features, (0, max_len - len(test_features)), 'constant')\n",
        "    prediction = perceptron.activate(padded_test_features)\n",
        "    parity = \"odd\" if prediction == 1 else \"even\"\n",
        "    print(f\"Number: {number_str}, Predicted Parity: {parity}\")\n",
        "\n",
        "print(\"\\nNote: This is a very basic example using a simplified feature representation.\")\n",
        "print(\"For robust recognition, more sophisticated feature engineering or a different neural network architecture would be required.\")\n",
        "print(\"The success of this simple model is highly dependent on the chosen features and the complexity of the task.\")\n",
        "print(\"Recognizing even/odd based purely on ASCII values of digits with a single perceptron is challenging and likely won't achieve high accuracy on unseen data.\")\n",
        "print(\"The purpose here is to illustrate the basic training and activation process of a Perceptron.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWhpiQbcmMDi",
        "outputId": "8d5387b7-a7da-4c6d-c602-d59d8ce4c7b9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing the Perceptron:\n",
            "Number: 12, Predicted Parity: odd\n",
            "Number: 13, Predicted Parity: odd\n",
            "Number: 100, Predicted Parity: odd\n",
            "Number: 101, Predicted Parity: odd\n",
            "Number: 25, Predicted Parity: odd\n",
            "Number: 36, Predicted Parity: odd\n",
            "\n",
            "Note: This is a very basic example using a simplified feature representation.\n",
            "For robust recognition, more sophisticated feature engineering or a different neural network architecture would be required.\n",
            "The success of this simple model is highly dependent on the chosen features and the complexity of the task.\n",
            "Recognizing even/odd based purely on ASCII values of digits with a single perceptron is challenging and likely won't achieve high accuracy on unseen data.\n",
            "The purpose here is to illustrate the basic training and activation process of a Perceptron.\n"
          ]
        }
      ]
    }
  ]
}